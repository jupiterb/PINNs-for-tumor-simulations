{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Brain-Tumor-Progression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ipywidgets import interact, IntSlider\n",
    "from pathlib import Path\n",
    "\n",
    "from imageprep.finder import BrainTumorProgressionDataFinder\n",
    "from imageprep.pipeline import DicomImagesLoader, StackImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../data/raw/Brain-Tumor-Progression\")\n",
    "data_finder = BrainTumorProgressionDataFinder(dataset_path)\n",
    "\n",
    "loader = DicomImagesLoader(data_finder)\n",
    "loader = StackImages(loader)\n",
    "\n",
    "loaded = list(loader.run())\n",
    "\n",
    "key = lambda item: f\"{item.labels[0]} {item.labels[1]}\"\n",
    "data = {key(item): {} for item in loaded}\n",
    "\n",
    "for item in loaded:\n",
    "    data[key(item)][item.labels[2]] = item.image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images types and shapes per study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes = {\n",
    "    id: {study_type: image.shape for study_type, image in studies.items()}\n",
    "    for id, studies in data.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes_df = pd.DataFrame(image_shapes).T.sort_index()\n",
    "image_shapes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_3d_image(image: np.ndarray):\n",
    "    def plot_image(x: int):\n",
    "        v_min = image.min()\n",
    "        v_max = image.max()\n",
    "\n",
    "        plt.imshow(image[x], vmin=v_min, vmax=v_max)\n",
    "        plt.show()\n",
    "\n",
    "    x_slider = IntSlider(min=0, max=image.shape[0] - 1, description=\"X\")\n",
    "    interact(plot_image, x=x_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512x512 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-004 1994-01-12\"][\"T1post\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 320x260 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-009 1991-01-03\"][\"T1post\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 320x280 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-003 1995-03-29\"][\"T1post\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 260x320 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-013 1989-09-18\"][\"T1post\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 256x256 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-011 1989-06-29\"][\"T1post\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on table and images above:\n",
    "- !st dimension of the images can be 22, 23 or 24. Assume it will be of 22 (taken from the selected end),\n",
    "- 2nd and 3rd dimensions of images are 512x512, 320x260, 320x280, 260x320, 256x256. It will be rescaled along 2nd dimension and cropped along 3rd dimension, to keep brain proportions,\n",
    "- 15 subjects have all 10 image types, there are 16 subjects have 9 image types in common, all subjects have 6 image types in common. To consider is whether more studies or more image types is needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
