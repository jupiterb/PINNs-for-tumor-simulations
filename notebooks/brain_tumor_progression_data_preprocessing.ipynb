{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain-Tumor-Progression dataset visualization and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from ipywidgets import interact, IntSlider\n",
    "from scipy import interpolate\n",
    "from typing import Any, Callable, Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DICOM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image = np.ndarray\n",
    "Study = dict[str, Image]\n",
    "Subject = dict[str, Study]\n",
    "Data = dict[str, Subject]\n",
    "\n",
    "Node = Image | Study | Subject | Data\n",
    "\n",
    "\n",
    "class ReUtils:\n",
    "    _subject = re.compile(r\"PGBM-\\d{3}\")\n",
    "    _date = re.compile(r\"(\\d{2}-\\d{2}-\\d{4})\")\n",
    "    _study = re.compile(r\"\\d+\\.\\d+-(\\w+)-\\d+\")\n",
    "    _dicom = re.compile(r\".*\\.dcm$\")\n",
    "\n",
    "    _folder_patterns = [_subject, _date, _study]\n",
    "\n",
    "    @staticmethod\n",
    "    def is_dicom(name: str) -> bool:\n",
    "        return ReUtils._dicom.match(name) is not None\n",
    "\n",
    "    @staticmethod\n",
    "    def folder_match(name: str) -> str:\n",
    "        for pattern in ReUtils._folder_patterns:\n",
    "            try:\n",
    "                return ReUtils._first_search(name, pattern)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        raise ValueError(f\"No pattern found in {name}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _first_search(text: str, pattern: re.Pattern) -> str:\n",
    "        match = pattern.search(text)\n",
    "\n",
    "        if match:\n",
    "            return match.group(pattern.groups)\n",
    "        else:\n",
    "            raise ValueError(f\"Cannot find pattern {pattern} in {text}.\")\n",
    "\n",
    "\n",
    "def load_dicom_images_folder(path: str) -> np.ndarray:\n",
    "    dicom_file_paths = [\n",
    "        os.path.join(path, file) for file in os.listdir(path) if ReUtils.is_dicom(file)\n",
    "    ]\n",
    "\n",
    "    dicom_files = [pydicom.dcmread(path) for path in dicom_file_paths]\n",
    "    dicom_files = sorted(dicom_files, key=lambda file: file.InstanceNumber)\n",
    "\n",
    "    dicom_images = [file.pixel_array for file in dicom_files]\n",
    "    images = np.stack(dicom_images)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def load_dataset(path: str) -> Node:\n",
    "    node = {}\n",
    "\n",
    "    for item in os.listdir(path):\n",
    "        try:\n",
    "            key = ReUtils.folder_match(item)\n",
    "            subnode_path = os.path.join(path, item)\n",
    "            node[key] = load_dataset(subnode_path)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return node if any(node) else load_dicom_images_folder(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: Data = load_dataset(\"../data/raw/Brain-Tumor-Progression\") # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images types and shapes per subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes_of_studies = {\n",
    "    f\"{subject} {date}\": {study: image.shape for study, image in images.items()}\n",
    "    for subject, node in data.items()\n",
    "    for date, images in node.items()\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shapes_of_studies_df = pd.DataFrame(image_shapes_of_studies).T.sort_index()\n",
    "image_shapes_of_studies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows that:\n",
    "- the height of the images can be 22, 23 or 24,\n",
    "- image resolutions are 512x512, 320x260, 320x280, 260x320, 256x256,\n",
    "- 15 subjects have all 10 image types, there are 16 subjects have 9 image types in common, all subjects have 6 image types in common.\n",
    "\n",
    "\n",
    "Taking this into account, the preprocessing function should: \n",
    "- assume a height of 22 (taken from the selected end), \n",
    "- stretch/crop images to one resolution, \n",
    "- consider subjects that have given image types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_3d_image(image):\n",
    "    def plot_height(x):\n",
    "        plt.imshow(image[x,:,:])\n",
    "        plt.title(f\"Height {x}\")\n",
    "        plt.show()\n",
    "\n",
    "    x_slider = IntSlider(min=0, max=image.shape[0] - 1, description=\"Height\")\n",
    "    interact(plot_height, x=x_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512x512 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-004\"][\"01-12-1994\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 320x260 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-009\"][\"01-03-1991\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 320x280 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-003\"][\"03-29-1995\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 260x320 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-013\"][\"09-18-1989\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 256x256 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data[\"PGBM-011\"][\"06-29-1989\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make shape common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_shape(node: Node) -> tuple[int, int, int]:\n",
    "    if isinstance(node, np.ndarray):\n",
    "        h, l, w = node.shape[0:3] # Height, long, width\n",
    "        return h, l, w\n",
    "    else:\n",
    "        shapes = [get_target_shape(n) for n in node.values()]\n",
    "        min_sizes = [min(sizes) for sizes in zip(*shapes)]\n",
    "        return tuple(min_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = get_target_shape(data)\n",
    "target_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_width_2d(image: np.ndarray, width: int) -> np.ndarray:\n",
    "    L, W = image.shape\n",
    "\n",
    "    if width > W:\n",
    "        left_pad = (width - W) // 2\n",
    "        right_pad = W + left_pad\n",
    "        new_image = np.zeros((L, width))\n",
    "        new_image[:, left_pad:right_pad] = image\n",
    "    elif width < W:\n",
    "        crop_start = (W - width) // 2\n",
    "        crop_end = crop_start + width\n",
    "        new_image = image[:, crop_start:crop_end]\n",
    "    else:\n",
    "        new_image = image\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def rescale_long_2d(image: np.ndarray, long: int) -> np.ndarray:\n",
    "    L, W = image.shape\n",
    "    W_temp = int(long / L * W)\n",
    "\n",
    "    x = np.arange(0, W)\n",
    "    y = np.arange(0, L)\n",
    "\n",
    "    new_x = np.linspace(0, W - 1, W_temp)\n",
    "    new_y = np.linspace(0, L - 1, long)\n",
    "\n",
    "    interpolator = interpolate.interp2d(x, y, image, kind=\"linear\")\n",
    "\n",
    "    return interpolator(new_x, new_y)\n",
    "\n",
    "\n",
    "def reshape_3d(image_3d: np.ndarray, height: int, long: int, width: int) -> np.ndarray:\n",
    "    images_2d = []\n",
    "\n",
    "    for image in image_3d[:height]:\n",
    "        image = rescale_long_2d(image, long)\n",
    "        image = resize_width_2d(image, width)\n",
    "        images_2d.append(image)\n",
    "\n",
    "    return np.stack(images_2d)\n",
    "\n",
    "\n",
    "def change_shape(node: Node, height: int, long: int, width: int) -> Node:\n",
    "    if isinstance(node, np.ndarray):\n",
    "        return reshape_3d(node, height, long, width)\n",
    "    else:\n",
    "        return {\n",
    "            key: change_shape(sub_node, height, long, width)\n",
    "            for key, sub_node in node.items()\n",
    "        } # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, long, _ = target_shape\n",
    "data_reshaped = change_shape(data, height, long, long) # Make long and width the same - will be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512x512 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data_reshaped[\"PGBM-004\"][\"01-12-1994\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 320x260 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data_reshaped[\"PGBM-009\"][\"01-03-1991\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 320x280 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data_reshaped[\"PGBM-003\"][\"03-29-1995\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 260x320 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data_reshaped[\"PGBM-013\"][\"09-18-1989\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 256x256 resolution examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_3d_image(data_reshaped[\"PGBM-011\"][\"06-29-1989\"][\"T1post\"]) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack images and store in HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_keys(d: dict[str, Any], possible_keys: Sequence[str]) -> bool:\n",
    "    actual_keys = set(d.keys())\n",
    "    return all([k in actual_keys for k in possible_keys])\n",
    "\n",
    "\n",
    "def stack_images(\n",
    "    images: dict[str, np.ndarray], order_function: Callable[[str], Any]\n",
    ") -> np.ndarray:\n",
    "    pairs = [(key, image) for key, image in images.items()]\n",
    "    pairs_sorted = sorted(pairs, key=lambda pair: order_function(pair[0]))\n",
    "    images_sorted = [image for _, image in pairs_sorted]\n",
    "    return np.stack(images_sorted)\n",
    "\n",
    "\n",
    "def get_date(date_str: str) -> datetime:\n",
    "    return datetime.strptime(date_str, \"%m-%d-%Y\")\n",
    "\n",
    "\n",
    "def get_time_data(data: Data) -> np.ndarray:\n",
    "    time_data = {\n",
    "        subject: sorted([get_date(date) for date in node.keys()])\n",
    "        for subject, node in data.items()\n",
    "    }\n",
    "\n",
    "    time_deltas = {\n",
    "        subject: np.array([(dates[i - 1] - dates[i]).days for i in range(1, len(dates))])\n",
    "        for subject, dates in time_data.items()\n",
    "    }\n",
    "\n",
    "    return stack_images(time_deltas, lambda x: x)\n",
    "\n",
    "\n",
    "def preprocess(data: Data, image_types: Sequence[str], target_path: str):\n",
    "    data_filtered = {\n",
    "        subject: {\n",
    "            date: {image_type: image for image_type, image in study.items()}\n",
    "            for date, study in node.items()\n",
    "        }\n",
    "        for subject, node in data.items()\n",
    "        if all([all_keys(study, image_types) for study in node.values()])\n",
    "    }\n",
    "\n",
    "    studies_stacked = {\n",
    "        subject: {\n",
    "            date: stack_images(images, lambda x: x) for date, images in node.items()\n",
    "        }\n",
    "        for subject, node in data_filtered.items()\n",
    "    }\n",
    "\n",
    "    dates_stacked = {\n",
    "        subject: stack_images(images, get_date)\n",
    "        for subject, images in studies_stacked.items()\n",
    "    }\n",
    "\n",
    "    all_stacked = stack_images(dates_stacked, lambda x: x)\n",
    "\n",
    "    time_data = get_time_data(data)\n",
    "\n",
    "    image_types_array = np.array(image_types, dtype=\"S\")\n",
    "\n",
    "    target_directory = os.path.dirname(target_path)\n",
    "\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "\n",
    "    with h5py.File(target_path, \"w\") as file:\n",
    "        file.create_dataset(\"images\", data=all_stacked)\n",
    "        file.create_dataset(\"times\", data=time_data)\n",
    "        file.create_dataset(\"metadata\", data=image_types_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = [\n",
    "    \"dT1\",\n",
    "    \"T1post\",\n",
    "    \"T2reg\",\n",
    "    \"MaskTumor\",\n",
    "    \"sRCBVreg\",\n",
    "    \"FLAIRreg\",\n",
    "    \"ADCreg\",\n",
    "    \"T1prereg\",\n",
    "    \"nRCBVreg\",\n",
    "    \"nCBFreg\",\n",
    "]\n",
    "\n",
    "preprocess(\n",
    "    data_reshaped, image_types, \"../data/preprocessed/Brain-Tumor-Progression/test.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
